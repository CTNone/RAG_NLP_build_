{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clean data"
      ],
      "metadata": {
        "id": "YxX1Phh7zHEM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "401mFzI-yfs6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install regex"
      ],
      "metadata": {
        "id": "4wh4dL84zOIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import json\n",
        "# import re\n",
        "# import os\n",
        "# import unicodedata\n",
        "\n",
        "# # Đường dẫn tệp đầu vào và đầu ra\n",
        "# INPUT_FILE = \"pittsburgh_data\"\n",
        "# OUTPUT_DIR = \"pittsburgh_data_cleaned\"\n",
        "# OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"history_000_cleaned.json\")\n",
        "\n",
        "# # Tạo thư mục đầu ra nếu chưa tồn tại\n",
        "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# # Hàm làm sạch văn bản\n",
        "# def clean_text(text):\n",
        "#     # Chuẩn hóa Unicode về dạng NFC (đảm bảo UTF-8 nhất quán)\n",
        "#     text = unicodedata.normalize('NFC', text)\n",
        "\n",
        "#     # Loại bỏ ký tự đặc biệt không cần thiết (giữ lại chữ cái, số, dấu câu cơ bản)\n",
        "#     text = re.sub(r'[^\\w\\s.,!?()-]', ' ', text)\n",
        "\n",
        "#     # Loại bỏ các đoạn quảng cáo hoặc thông tin không liên quan của Wikipedia\n",
        "#     text = re.sub(r'Jump to content|Coordinates:.*?\\n|From Wikipedia, the free encyclopedia|This article is about.*?For other uses,.*?disambiguation\\)|Not to be confused.*?\\n', '', text, flags=re.DOTALL)\n",
        "\n",
        "#     # Loại bỏ các liên kết nội bộ hoặc chú thích của Wikipedia\n",
        "#     text = re.sub(r'\\[\\d+\\]|\\[edit\\]|See also:.*?\\n', '', text)\n",
        "\n",
        "#     # Loại bỏ khoảng trắng dư thừa và dòng trống\n",
        "#     text = re.sub(r'\\n+', '\\n', text)\n",
        "#     text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "#     # Chuẩn hóa dấu câu\n",
        "#     text = re.sub(r'\\s+([.,!?])', r'\\1', text)\n",
        "\n",
        "#     return text\n",
        "\n",
        "# Hàm xử lý 1 tệp JSON\n",
        "# def clean_json_file(input_file, output_file):\n",
        "#     try:\n",
        "#         # Đọc tệp JSON\n",
        "#         with open(input_file, 'r', encoding='utf-8') as f:\n",
        "#             data = json.load(f)\n",
        "\n",
        "#         # Làm sạch trường content\n",
        "#         if 'content' in data:\n",
        "#             data['content'] = clean_text(data['content'])\n",
        "\n",
        "#         # Lưu tệp JSON đã làm sạch\n",
        "#         with open(output_file, 'w', encoding='utf-8') as f:\n",
        "#             json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "#         print(f\"Đã làm sạch và lưu tệp tại: {output_file}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Lỗi khi xử lý tệp {input_file}: {e}\")\n",
        "\n",
        "# # Chạy hàm chính\n",
        "# if __name__ == \"__main__\":\n",
        "#     clean_json_file(INPUT_FILE, OUTPUT_FILE)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hv8HMM-fzPuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "\n",
        "# Đường dẫn thư mục đầu vào và đầu ra\n",
        "INPUT_DIR = \"pittsburgh_data\"\n",
        "OUTPUT_DIR = \"pittsburgh_data/cleaned\"\n",
        "\n",
        "# Tạo thư mục đầu ra nếu chưa tồn tại\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Hàm làm sạch văn bản\n",
        "def clean_text(text):\n",
        "    # Chuẩn hóa Unicode về dạng NFC (đảm bảo UTF-8 nhất quán)\n",
        "    text = unicodedata.normalize('NFC', text)\n",
        "\n",
        "    # Loại bỏ ký tự đặc biệt không cần thiết (giữ lại chữ cái, số, dấu câu cơ bản)\n",
        "    text = re.sub(r'[^\\w\\s.,!?()-]', ' ', text)\n",
        "\n",
        "    # Loại bỏ các đoạn quảng cáo hoặc thông tin không liên quan của Wikipedia\n",
        "    text = re.sub(r'Jump to content|Coordinates:.*?\\n|From Wikipedia, the free encyclopedia|This article is about.*?For other uses,.*?disambiguation\\)|Not to be confused.*?\\n', '', text, flags=re.DOTALL)\n",
        "\n",
        "    # Loại bỏ các liên kết nội bộ hoặc chú thích của Wikipedia\n",
        "    text = re.sub(r'\\[\\d+\\]|\\[edit\\]|See also:.*?\\n', '', text)\n",
        "\n",
        "    # Loại bỏ khoảng trắng dư thừa và dòng trống\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "    # Chuẩn hóa dấu câu\n",
        "    text = re.sub(r'\\s+([.,!?])', r'\\1', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Hàm làm sạch một tệp JSON\n",
        "def clean_json_file(input_file, output_file):\n",
        "    try:\n",
        "        # Đọc tệp JSON\n",
        "        with open(input_file, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Làm sạch trường content\n",
        "        if 'content' in data:\n",
        "            data['content'] = clean_text(data['content'])\n",
        "\n",
        "        # Lưu tệp JSON đã làm sạch\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"Đã làm sạch và lưu tệp tại: {output_file}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi xử lý tệp {input_file}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Hàm làm sạch tất cả tệp JSON trong thư mục\n",
        "def clean_all_files(input_dir, output_dir):\n",
        "    processed_files = 0\n",
        "    failed_files = 0\n",
        "\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith('.json') and not filename.startswith('url_list'):\n",
        "            input_file = os.path.join(input_dir, filename)\n",
        "            output_file = os.path.join(output_dir, filename.replace('.json', '_cleaned.json'))\n",
        "\n",
        "            if clean_json_file(input_file, output_file):\n",
        "                processed_files += 1\n",
        "            else:\n",
        "                failed_files += 1\n",
        "\n",
        "    print(f\"Hoàn thành! Đã xử lý {processed_files} tệp, lỗi {failed_files} tệp.\")\n",
        "    print(f\"Kết quả được lưu tại: {output_dir}\")\n",
        "\n",
        "# Chạy hàm chính\n",
        "if __name__ == \"__main__\":\n",
        "    clean_all_files(INPUT_DIR, OUTPUT_DIR)\n"
      ],
      "metadata": {
        "id": "85qmRXTSzTHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải thư mục pittsburgh xuống thành file zip"
      ],
      "metadata": {
        "id": "weLI1MH9zXDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('pittsburgh_data', 'zip', 'pittsburgh_data')\n"
      ],
      "metadata": {
        "id": "35mpE85UzXw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('pittsburgh_data.zip')\n"
      ],
      "metadata": {
        "id": "R3R-Rce1za-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chia đoạn văn 200-500 ký tự (CHUNKING) + phát hiện thông tin quan trọng"
      ],
      "metadata": {
        "id": "0wCaVDzCzn4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Tải dữ liệu NLTK (cần cho phân tách câu)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# Đường dẫn thư mục đầu vào và đầu ra\n",
        "# INPUT_DIR = \"pittsburgh_data/cleaned\"\n",
        "# OUTPUT_DIR = \"pittsburgh_data/segmented\"\n",
        "INPUT_DIR = \"MAIN_DATA/cleaned\"\n",
        "OUTPUT_DIR = \"MAIN_DATA/segmented\"\n",
        "REPORT_FILE = os.path.join(OUTPUT_DIR, \"integrity_report.json\")\n",
        "\n",
        "# Tạo thư mục đầu ra nếu chưa tồn tại\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Hàm chia văn bản thành các đoạn (200-500 từ)\n",
        "def split_into_chunks(text, min_words=200, max_words=500):\n",
        "    # Phân tách văn bản thành các câu\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    word_count = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence)\n",
        "        word_count += len(words)\n",
        "        current_chunk.append(sentence)\n",
        "\n",
        "        # Nếu số từ vượt quá giới hạn tối đa, lưu đoạn\n",
        "        if word_count >= min_words:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "            word_count = 0\n",
        "\n",
        "    # Lưu đoạn cuối nếu có đủ từ\n",
        "    if current_chunk and word_count >= min_words:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    elif current_chunk and chunks:  # Gộp vào đoạn trước nếu không đủ từ\n",
        "        chunks[-1] += ' ' + ' '.join(current_chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Hàm kiểm tra tính toàn vẹn (phát hiện thông tin quan trọng)\n",
        "def check_integrity(text):\n",
        "    issues = []\n",
        "\n",
        "    # Kiểm tra thông tin ngày tháng (ví dụ: \"June 2025\", \"12/31/2025\")\n",
        "    date_patterns = [\n",
        "        r'\\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},\\s+\\d{4}\\b',\n",
        "        r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b',\n",
        "        r'\\b\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{4}\\b'\n",
        "    ]\n",
        "    dates_found = []\n",
        "    for pattern in date_patterns:\n",
        "        dates_found.extend(re.findall(pattern, text))\n",
        "\n",
        "    if not dates_found:\n",
        "        issues.append(\"Không tìm thấy thông tin ngày tháng (có thể thiếu ngày sự kiện).\")\n",
        "    else:\n",
        "        issues.append(f\"Đã tìm thấy {len(dates_found)} ngày tháng: {', '.join(dates_found)}\")\n",
        "\n",
        "    # Kiểm tra tên sự kiện/lễ hội (tìm các cụm từ như \"Festival\", \"Event\", tên in hoa)\n",
        "    event_patterns = [\n",
        "        r'\\b[A-Z][a-zA-Z\\s]*(?:Festival|Event|Celebration)\\b',\n",
        "        r'\\bPittsburgh\\s+[A-Z][a-zA-Z\\s]*(?:Festival|Event)\\b'\n",
        "    ]\n",
        "    events_found = []\n",
        "    for pattern in event_patterns:\n",
        "        events_found.extend(re.findall(pattern, text))\n",
        "\n",
        "    if not events_found:\n",
        "        issues.append(\"Không tìm thấy tên sự kiện/lễ hội.\")\n",
        "    else:\n",
        "        issues.append(f\"Đã tìm thấy {len(events_found)} sự kiện: {', '.join(events_found)}\")\n",
        "\n",
        "    return issues\n",
        "\n",
        "# Hàm xử lý một tệp JSON\n",
        "def process_json_file(input_file, output_dir):\n",
        "    try:\n",
        "        # Đọc tệp JSON\n",
        "        with open(input_file, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Kiểm tra tính toàn vẹn\n",
        "        integrity_issues = check_integrity(data.get('content', ''))\n",
        "\n",
        "        # Chia nội dung thành các đoạn\n",
        "        chunks = split_into_chunks(data.get('content', ''))\n",
        "\n",
        "        # Lưu các đoạn vào tệp JSON mới\n",
        "        output_data = {\n",
        "            'url': data.get('url', ''),\n",
        "            'title': data.get('title', ''),\n",
        "            'chunks': chunks,\n",
        "            'integrity_issues': integrity_issues\n",
        "        }\n",
        "\n",
        "        output_file = os.path.join(output_dir, os.path.basename(input_file).replace('.json', '_segmented.json'))\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"Đã xử lý và lưu tệp tại: {output_file}\")\n",
        "        return output_data\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi xử lý tệp {input_file}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Hàm xử lý tất cả tệp JSON trong thư mục\n",
        "def process_all_files(input_dir, output_dir):\n",
        "    report = []\n",
        "    processed_files = 0\n",
        "    failed_files = 0\n",
        "\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith('.json'):\n",
        "            input_file = os.path.join(input_dir, filename)\n",
        "            result = process_json_file(input_file, output_dir)\n",
        "            if result:\n",
        "                report.append({\n",
        "                    'file': filename,\n",
        "                    'url': result['url'],\n",
        "                    'chunk_count': len(result['chunks']),\n",
        "                    'integrity_issues': result['integrity_issues']\n",
        "                })\n",
        "                processed_files += 1\n",
        "            else:\n",
        "                failed_files += 1\n",
        "\n",
        "    # Lưu báo cáo tính toàn vẹn\n",
        "    with open(REPORT_FILE, 'w', encoding='utf-8') as f:\n",
        "        json.dump(report, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Hoàn thành! Đã xử lý {processed_files} tệp, lỗi {failed_files} tệp.\")\n",
        "    print(f\"Báo cáo tính toàn vẹn được lưu tại: {REPORT_FILE}\")\n",
        "\n",
        "# Chạy hàm chính\n",
        "if __name__ == \"__main__\":\n",
        "    process_all_files(INPUT_DIR, OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JXbJOjCznM7",
        "outputId": "82293c9e-cf4c-4faf-efed-57d362a73c4e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_6_https___web_archive_org_web_20140202184957_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_16_https___en_wikipedia_org_wiki_Pittsburgh_Public_Sc_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_38_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_35_https___web_archive_org_web_20171202203212_https___cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_49_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_34_https___web_archive_org_web_20180720225524_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_15_https___en_wikipedia_org_wiki_List_of_Pittsburgh_n_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_39_https___web_archive_org_web_20220421001139_https___cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_27_https___en_wikipedia_org_wiki_Pittsburgh_Penguins_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_54_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_28_https___web_archive_org_web_20180429024134_https___cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_46_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_79_https___www_duq_edu_about_history_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_43_https___web_archive_org_web_20070925225807_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_86_https___www_discovertheburgh_com__cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_60_https___web_archive_org_web_20060831013104_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_31_https___web_archive_org_web_20081104015950_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_2_https___upittpress_org_wp-content_uploads_2019_01__cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_51_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_33_https___en_wikipedia_org_wiki_Pittsburgh_Post-Gaze_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_53_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_78_https___www_nhl_com_penguins_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_1_https___en_wikipedia_org_wiki_Pittsburgh_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_12_https___en_wikipedia_org_wiki_Sports_in_Pittsburgh_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_30_https___web_archive_org_web_20160304091955_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_37_https___en_wikipedia_org_wiki_University_of_Pittsb_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_7_https___aeg_memberclicks_net_assets_docs_Geology_2_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_56_https___web_archive_org_web_20090305002146_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_41_https___web_archive_org_web_20161013224703_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_67_https___web_archive_org_web_20190629152515_https___cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_77_https___www_steelers_com__cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_29_https___en_wikipedia_org_wiki_Pittsburgh_Internati_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_63_https___web_archive_org_web_20080414064549_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_68_https___web_archive_org_web_20160304094015_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_72_https___web_archive_org_web_20160327135452_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_74_https___www_allrecipes_com_what-is-pittsburgh-sala_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_17_https___en_wikipedia_org_wiki_Economy_of_Pittsburg_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_48_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_71_https___web_archive_org_web_20110725202935_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_61_https___web_archive_org_web_20110523130245_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_83_https___www_neighborhoodscout_com_pa_pittsburgh_cr_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_42_https___web_archive_org_web_20110710205520_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_64_https___web_archive_org_web_20080414064613_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_85_https___www_post-gazette_com_local_pittsburgh-hist_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_25_https___en_wikipedia_org_wiki_Pittsburgh_Pirates_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_8_https___web_archive_org_web_20070927220849_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_4_https___www_americanimmigrationcouncil_org_sites_d_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_84_https___www_phipps_conservatory_org__cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_13_https___web_archive_org_web_20080528074040_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_14_http___fs_ncaa_org_Docs_stats_m_basketball_RB_2009_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_80_https___www_pghworks_com__cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_19_https___web_archive_org_web_20101025123027_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_62_https___web_archive_org_web_20130602201604_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_36_https___en_wikipedia_org_wiki_Pittsburgh_Marathon_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_82_http___www_weather_gov_media_hazardsimplification__cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_10_https___en_wikipedia_org_wiki_History_of_Pittsburg_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_47_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_3_https___www_weather_gov_media_pbz_records_prec_pdf_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_44_https___web_archive_org_web_20130403033143_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_66_https___web_archive_org_web_20080414064652_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_81_https___www_weather_gov_pbz_climate_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_69_https___en_wikipedia_org_wiki_Pittsburgh_Regional__cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_21_https___web_archive_org_web_20140202184957_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_20_http___www_alleghenyplaces_com_docs_DraftPlan_Chap_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_23_https___static_www_nfl_com_image_upload_league_app_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_40_https___www_brand_pitt_edu_sites_default_files_pit_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_18_http___www_phmc_state_pa_us_Portal_Communities_BHP_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_26_https___en_wikipedia_org_wiki_Pittsburgh_synagogue_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_52_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_65_https___web_archive_org_web_20080414064640_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_57_https___web_archive_org_web_20131029193230_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_50_https___www_ir_pitt_edu_sites_default_files_assets_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_5_https___web_archive_org_web_20191221235539_https___cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_9_http___aapa_files_cms-plus_com_PDFs_2011_20U_20S_2_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_45_https___web_archive_org_web_20090115041744_http____cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_11_https___en_wikipedia_org_wiki_Culture_of_Pittsburg_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_22_https___en_wikipedia_org_wiki_Pittsburgh_Steelers_cleaned_segmented.json\n",
            "Đã xử lý và lưu tệp tại: MAIN_DATA/segmented/doc_70_https___www_apta_com_wp-content_uploads_2024-Q4-Ri_cleaned_segmented.json\n",
            "Hoàn thành! Đã xử lý 78 tệp, lỗi 0 tệp.\n",
            "Báo cáo tính toàn vẹn được lưu tại: MAIN_DATA/segmented/integrity_report.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('MAIN_DATA', 'zip', 'MAIN_DATA')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lYjSJFGH42oE",
        "outputId": "ea501b4f-1347-473e-9e72-07ad130c96c0",
        "collapsed": true
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/MAIN_DATA.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('MAIN_DATA.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WYrnb-gGby1z",
        "outputId": "20c85ed8-ca40-413e-999b-735e6e663ab2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_68ea3156-e96f-4327-84cc-7f41fd50cdfa\", \"MAIN_DATA.zip\", 8300643)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}